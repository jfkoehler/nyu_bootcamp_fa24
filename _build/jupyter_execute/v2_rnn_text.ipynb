{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkMGC5qF6_Bw"
   },
   "source": [
    "# Text Classification and Recurrent Neural Networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6p825gZz1pky"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1V3dAQ5T1ph8",
    "outputId": "009b1157-b348-498a-f6e1-3ab6dc7315fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.1.0)\r\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (3.13.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (1.26.4)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (15.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\r\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (3.11.9)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.26.3)\r\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (23.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (6.0.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->datasets) (4.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Var0y0mO1pf8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"Paul/hatecheck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JCgkDaBR1pcs"
   },
   "outputs": [],
   "source": [
    "df = ds['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "0rGV2gGr1pZ-",
    "outputId": "e6841ba8-2df5-401d-b784-c905b85a1020"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              I hate women. \n",
       "1       I hate trans people. \n",
       "2         I hate gay people. \n",
       "3       I hate black people. \n",
       "4    I hate disabled people. \n",
       "Name: test_case, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['test_case'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "CyvCAU_w1pXg",
    "outputId": "969210f9-d831-4a1d-953b-a4296e132693"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_gold\n",
       "hateful        2563\n",
       "non-hateful    1165\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_gold'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JeOT3Un2JnL"
   },
   "source": [
    "### Encoding the Text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xC5Dl3xX1pVX"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8l-hCCFo1pTL"
   },
   "outputs": [],
   "source": [
    "cvect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "X4Kkp-7W1pQT"
   },
   "outputs": [],
   "source": [
    "dtm = cvect.fit_transform(df['test_case'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "GUAyYobT2ttp",
    "outputId": "e6da105f-8e12-4e5c-fc12-06f4a403130a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2020</th>\n",
       "      <th>4ssholes</th>\n",
       "      <th>abhor</th>\n",
       "      <th>about</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutefilth</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>academics</th>\n",
       "      <th>accepted</th>\n",
       "      <th>accountants</th>\n",
       "      <th>...</th>\n",
       "      <th>writing</th>\n",
       "      <th>wrong</th>\n",
       "      <th>yeah</th>\n",
       "      <th>years</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yourselves</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2020  4ssholes  abhor  about  absolute  absolutefilth  absolutely  \\\n",
       "0     0         0      0      0         0              0           0   \n",
       "1     0         0      0      0         0              0           0   \n",
       "2     0         0      0      0         0              0           0   \n",
       "3     0         0      0      0         0              0           0   \n",
       "4     0         0      0      0         0              0           0   \n",
       "\n",
       "   academics  accepted  accountants  ...  writing  wrong  yeah  years  you  \\\n",
       "0          0         0            0  ...        0      0     0      0    0   \n",
       "1          0         0            0  ...        0      0     0      0    0   \n",
       "2          0         0            0  ...        0      0     0      0    0   \n",
       "3          0         0            0  ...        0      0     0      0    0   \n",
       "4          0         0            0  ...        0      0     0      0    0   \n",
       "\n",
       "   your  yours  yourself  yourselves  zoo  \n",
       "0     0      0         0           0    0  \n",
       "1     0      0         0           0    0  \n",
       "2     0      0         0           0    0  \n",
       "3     0      0         0           0    0  \n",
       "4     0      0         0           0    0  \n",
       "\n",
       "[5 rows x 1292 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dtm.toarray(), columns=cvect.get_feature_names_out()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xP_yzIBC1pNS"
   },
   "outputs": [],
   "source": [
    "X = dtm\n",
    "y = df['label_gold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrZ7TjOH2Zak"
   },
   "source": [
    "### Problem\n",
    "\n",
    "Split the data and build a random forest classifier on the training data.  Compare the train and test scores.  \n",
    "\n",
    "- What words were most important in making the classifications?\n",
    "- What elements of the CountVectorizer might you change or grid search to attempt to improve your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "id": "QjOyryQn2ZIB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "id": "fl7NA5Ek2ZE6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "id": "uwZqNLIv2ZBy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "id": "n937sewV2Y-d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "id": "p9kzCXAQ2Y7Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "id": "jYVIyq1m2Y4h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SQWyog0AAOZ"
   },
   "source": [
    "# Text Classification with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "e0uc39GMhd70"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "id": "SsI9cVkeLglh"
   },
   "outputs": [],
   "source": [
    "y = np.where(y == 'hateful', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "id": "WLzaOkDoLGUQ"
   },
   "outputs": [],
   "source": [
    "Xt = torch.tensor(X.todense(), dtype = torch.float32)\n",
    "yt = torch.tensor(y, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u5t9Sn_vLGI1",
    "outputId": "031a33bc-d6a8-4a77-b031-4321b4946187"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "id": "rmRBaRuBLGDo"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(in_features=Xt.shape[1], out_features=1),\n",
    "                      nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "id": "TO6yoSU2LF-7"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y0aF8Hx9LF7A",
    "outputId": "0b8ab37d-fcc9-48f0-aa67-e32420456528"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.6889792680740356\n",
      "Epoch 10 Loss: 0.5407963991165161\n",
      "Epoch 20 Loss: 0.457720011472702\n",
      "Epoch 30 Loss: 0.39816051721572876\n",
      "Epoch 40 Loss: 0.3553771674633026\n",
      "Epoch 50 Loss: 0.3219773471355438\n",
      "Epoch 60 Loss: 0.295131117105484\n",
      "Epoch 70 Loss: 0.27274569869041443\n",
      "Epoch 80 Loss: 0.25362011790275574\n",
      "Epoch 90 Loss: 0.23695124685764313\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "  yhat = model(Xt)\n",
    "  loss = loss_fn(yhat, yt.unsqueeze(1))\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  if epoch % 10 == 0:\n",
    "    print(f'Epoch {epoch} Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "id": "Pfzj84OiL6CX"
   },
   "outputs": [],
   "source": [
    "preds = torch.where(model(Xt) > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9OAgH2kTL6Ap",
    "outputId": "22d68378-d352-49f0-8fbd-d543bd440753"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9372)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds.flatten() == yt).sum()/len(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "id": "s-jE81MaL51b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "id": "liI1vRV8hg2F"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "id": "XOqnZA90i0vQ"
   },
   "outputs": [],
   "source": [
    "#create a tokenizer\n",
    "tokenizer = Tokenizer(num_words = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "id": "XUWmDd-ik7MK"
   },
   "outputs": [],
   "source": [
    "#fit the tokenizer\n",
    "tokenizer.fit_on_texts(df['test_case'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "id": "ZIs8UShtsfpg"
   },
   "outputs": [],
   "source": [
    "#create document term matrix (binarized)\n",
    "dtm = tokenizer.texts_to_matrix(df['test_case'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJc6IxLe8cea",
    "outputId": "f48eab4f-aa99-45d4-ed5e-e4d466e38158"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a peek\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Q_WhuHe2CTPz",
    "outputId": "205ab9ae-6bdc-4824-dd70-60836388f2bc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'I hate gay people. '"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['test_case'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "id": "iDtzLOGbDvwQ"
   },
   "outputs": [],
   "source": [
    "X = dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "id": "sK-ekzymqkc3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "aszcYuSVqkVo"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzIechzNqkR1",
    "outputId": "cb14397d-3d7b-4f45-ec07-a9563de6e310"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "id": "08tt_Zx3Ot8t"
   },
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype = torch.float)\n",
    "X_test = torch.tensor(X_test, dtype = torch.float)\n",
    "y_train = torch.tensor(y_train, dtype = torch.float)\n",
    "y_test = torch.tensor(y_test, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "bpsixqUc8emJ"
   },
   "outputs": [],
   "source": [
    "#model definition\n",
    "class TextModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.lin1 = nn.Linear(in_features = 500, out_features = 100)\n",
    "    self.lin2 = nn.Linear(100, 100)\n",
    "    self.lin3 = nn.Linear(100, 1)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.act = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.act(self.lin1(x))\n",
    "    x = self.act(self.lin2(x))\n",
    "    return self.sigmoid(self.lin3(x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "4h0spe_p8eie"
   },
   "outputs": [],
   "source": [
    "#ingredients\n",
    "model = TextModel()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXpxaYe88ece",
    "outputId": "3e5ac0b9-a8cb-42f5-bb60-48d63bc8a1fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 60.102640464901924\n",
      "Epoch 10 Loss: 60.102640464901924\n",
      "Epoch 20 Loss: 60.102640464901924\n",
      "Epoch 30 Loss: 60.102640464901924\n",
      "Epoch 40 Loss: 60.102640464901924\n",
      "Epoch 50 Loss: 60.102640464901924\n",
      "Epoch 60 Loss: 60.102640464901924\n",
      "Epoch 70 Loss: 60.102640464901924\n",
      "Epoch 80 Loss: 60.102640464901924\n",
      "Epoch 90 Loss: 60.102640464901924\n"
     ]
    }
   ],
   "source": [
    "#evaluate\n",
    "for epoch in range(100):\n",
    "  yhat = model(X_train)\n",
    "  y = y_train.reshape(-1, 1)\n",
    "  loss = loss_fn(yhat, y)\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  if epoch % 10 == 0:\n",
    "    print(f'Epoch {epoch} Loss: {losses}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_DcEHs4y8eZn",
    "outputId": "9e552cb6-9f84-434d-f08c-0843ddf09cba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-269-ada0177efcd4>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Xt = torch.tensor(X_test, dtype = torch.float)\n"
     ]
    }
   ],
   "source": [
    "Xt = torch.tensor(X_test, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "id": "aEy8zfP0HNr5"
   },
   "outputs": [],
   "source": [
    "output = model(Xt) #model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "-GVJHCGeqEJM",
    "outputId": "25e56f69-ecd4-495f-ca26-ad40ea2c9ee8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.3895e-13],\n",
       "        [6.5180e-06],\n",
       "        [9.9800e-01],\n",
       "        [1.0000e+00],\n",
       "        [6.9652e-16]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "id": "DkVQymo1HUui"
   },
   "outputs": [],
   "source": [
    "#Converting probabilities to prediction\n",
    "preds = np.where(np.array(output.detach()) >= .5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhEbGWR8HUnh",
    "outputId": "11891fe2-0d3a-4126-a4ef-5b1f6dcb282e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(746, 1)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pFqddE7iNsRp",
    "outputId": "a2da9e30-036e-4bed-bffa-f20a3d8ee5a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([746])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppU6XUcLHrgv",
    "outputId": "09681a5b-6c10-4c44-c532-67e14d43644f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9651)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds.flatten() == y_test.flatten()).sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "id": "Zy3fuAQiOyVi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "id": "8xvnYrodOyQm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "id": "g5b32EtLOyNI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zajZdySD9Lxl"
   },
   "source": [
    "### Basic RNN\n",
    "\n",
    "![](https://karpathy.github.io/assets/rnn/diags.jpeg)\n",
    "\n",
    "[Source](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "id": "14ohZWmqlBXn"
   },
   "outputs": [],
   "source": [
    "#create sequences\n",
    "sequences = tokenizer.texts_to_sequences(df['test_case'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1iAvE73XlGNf",
    "outputId": "48935972-a3a4-4206-cac3-6bc651281470"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 96, 22]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at first sequence\n",
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WBoD5QfPlK7X",
    "outputId": "48294218-c8fa-43b3-ebc7-8d08f1e6c575"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'I hate trans people. '"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare to text\n",
    "df['test_case'].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "id": "PmeaiuOAlNGD"
   },
   "outputs": [],
   "source": [
    "#pad and make all same length\n",
    "sequences = pad_sequences(sequences, maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JH6zRxhxmlrt",
    "outputId": "9e5707c8-181e-462d-d936-0a27e6076311"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine results\n",
    "sequences[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dYw2vJpntRVx",
    "outputId": "676e6a47-487d-45d3-9e8a-6bf8275cf77d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  5, 96, 15,  1], dtype=int32)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "id": "7GnZn1epsSEi"
   },
   "outputs": [],
   "source": [
    "#example rnn\n",
    "rnn = nn.RNN(input_size = 30,\n",
    "             hidden_size = 30,\n",
    "             num_layers = 1,\n",
    "             batch_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fr2mNE_0swQp",
    "outputId": "9e9bf6ba-3bae-474e-eb45-27a700767122"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pass data through\n",
    "sample_sequence = torch.tensor(sequences[1],\n",
    "                               dtype = torch.float,\n",
    "                               ).reshape(1, -1)\n",
    "sample_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "id": "97X1o7qHmw5n"
   },
   "outputs": [],
   "source": [
    "#output\n",
    "output, hidden = rnn(sample_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ONbv5VGa2EhR",
    "outputId": "7555d8ba-49bd-4293-ca7b-7ef48df393c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9990, -1.0000,  1.0000, -0.6773, -1.0000, -1.0000, -0.9506, -0.1827,\n",
       "          1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  1.0000, -1.0000,\n",
       "         -0.8065,  0.9974, -0.6964, -1.0000,  0.7627,  1.0000, -1.0000, -1.0000,\n",
       "          1.0000,  0.9879,  1.0000,  1.0000, -1.0000,  1.0000]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hidden\n",
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyjoR6x1tIRz",
    "outputId": "bd7d14c3-42bc-4902-97e8-5adba19ecdb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linear layer\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "id": "wy86PysZh4yt"
   },
   "outputs": [],
   "source": [
    "#pass through linear\n",
    "lin1 = nn.Linear(in_features = 30, out_features = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H-24s8_ZMNQs",
    "outputId": "9e017534-afd6-43d7-b63b-3f32790701c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8009]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output to probability\n",
    "lin1(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6ix8-cXUZPM",
    "outputId": "e355e743-44a0-4796-87b1-a0adcf3b344b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6902]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(lin1(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Xs5vNYdUtIW",
    "outputId": "d0f539e0-cd36-4817-fa98-96d7382dbeec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2982, 500])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUhR_kGtUtED",
    "outputId": "52fd4a12-822e-479a-bfe7-38983a777149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2982])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "id": "BrtHwnqnPThV"
   },
   "outputs": [],
   "source": [
    "# model = nn.Sequential(nn.RNN(input_size = 30,hidden_size = 30, num_layers = 2, batch_first = True),\n",
    "#                       nn.Linear(in_features = 30, out_features = 1),\n",
    "#                       nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "id": "x0N9mpg9h5og"
   },
   "outputs": [],
   "source": [
    "#class\n",
    "class BasicRNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.rnn = nn.RNN(input_size = 30,\n",
    "                    hidden_size = 30,\n",
    "                    num_layers = 3,\n",
    "                    batch_first = False)\n",
    "    self.lin1 = nn.Linear(in_features = 30, out_features=30)\n",
    "    self.lin2 = nn.Linear(30, 100)\n",
    "    self.lin3 = nn.Linear(100, 1)\n",
    "    self.act = nn.ReLU()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x, _ = self.rnn(x)\n",
    "    x = self.act(self.lin1(x))\n",
    "    x = self.act(self.lin2(x))\n",
    "    x = self.sigmoid(self.lin3(x))\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "id": "um1Frj5lP7Dj"
   },
   "outputs": [],
   "source": [
    "y = np.where(df['label_gold'] == 'hateful', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CiRbgDMTRQEl",
    "outputId": "025e5421-2b05-40ee-90a4-58d1ef2a6109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3728, 30])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FkjaRnv2RS_m",
    "outputId": "9424533a-fcb9-4c40-d84f-24bdf5b431a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3728,)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "id": "Xv1ka2VsUjG1"
   },
   "outputs": [],
   "source": [
    "X = sequences\n",
    "X = torch.tensor(X, dtype = torch.float)\n",
    "y = torch.tensor(y, dtype = torch.float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "id": "4ACZI673-RpV"
   },
   "outputs": [],
   "source": [
    "#optimizer and loss\n",
    "model = BasicRNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLj-NUK5-TeE",
    "outputId": "aeb3d56e-83bf-4618-e24f-20bde0679203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 66.96763409674168\n",
      "Epoch 10 Loss: 72.60977609455585\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "for epoch in range(20):\n",
    "    yhat = model(X_train)\n",
    "    y = y_train.reshape(-1, 1)\n",
    "    loss = loss_fn(yhat, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses += loss.item()\n",
    "    if epoch % 10 == 0:\n",
    "      print(f'Epoch {epoch} Loss: {losses}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M_uQWrJaPRwA",
    "outputId": "ab7e20ed-535c-4b4f-c105-5e8b1483b55f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-332-ada0177efcd4>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Xt = torch.tensor(X_test, dtype = torch.float)\n"
     ]
    }
   ],
   "source": [
    "Xt = torch.tensor(X_test, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "id": "T5XcG1OpPZ2T"
   },
   "outputs": [],
   "source": [
    "output = model(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "id": "hwS2m5rcPZ2Z"
   },
   "outputs": [],
   "source": [
    "preds = np.where(np.array(output.detach()) >= .5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izZ6GyxHwV2z",
    "outputId": "9e071ef4-6fc4-4a00-8a6c-a387ae603e86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
       "        1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "        0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "        1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
       "        1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "        1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "        0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
       "        0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GEhgDz-9wiP0",
    "outputId": "44eb2a1f-bad0-4d59-817b-632c831631d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6139)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds.flatten() == y_test.flatten())/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0Yof-sAa6cU"
   },
   "source": [
    "Additional improvements to the RNN include the LSTM and GRU layers -- examples at end of notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouZw-ftC3tcn"
   },
   "source": [
    "### Pretrained Models and HuggingFace\n",
    "\n",
    "- [Huggingface](https://huggingface.co/)\n",
    "- [Chronos Paper](https://arxiv.org/abs/2403.07815)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUfs4IFd3od3"
   },
   "outputs": [],
   "source": [
    "pip install git+https://github.com/amazon-science/chronos-forecasting.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1DWaYOa93oRa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from chronos import ChronosPipeline\n",
    "\n",
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "  \"amazon/chronos-t5-large\",\n",
    "  device_map=\"cuda\",\n",
    "  torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/AileenNielsen/TimeSeriesAnalysisWithPython/master/data/AirPassengers.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "np9GE5ch3oNw"
   },
   "outputs": [],
   "source": [
    "# context must be either a 1D tensor, a list of 1D tensors,\n",
    "# or a left-padded 2D tensor with batch as the first dimension\n",
    "context = torch.tensor(df[\"#Passengers\"])\n",
    "prediction_length = 12\n",
    "forecast = pipeline.predict(context, prediction_length)  # shape [num_series, num_samples, prediction_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lbH7HgtW3oLS"
   },
   "outputs": [],
   "source": [
    "# visualize the forecast\n",
    "forecast_index = range(len(df), len(df) + prediction_length)\n",
    "low, median, high = np.quantile(forecast[0].numpy(), [0.1, 0.5, 0.9], axis=0)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(df[\"#Passengers\"], color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(forecast_index, median, color=\"tomato\", label=\"median forecast\")\n",
    "plt.fill_between(forecast_index, low, high, color=\"tomato\", alpha=0.3, label=\"80% prediction interval\")\n",
    "plt.legend()\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCp8SfBdN4El"
   },
   "source": [
    "### Problem\n",
    "\n",
    "Explore the pretrained models available and try to find one that is either of relevance to your final paper or just of general interest.  Load and use the model in an example -- even just the docs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfk8Kugz3oHz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtsjogUW3oF6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9agE6Oi3oDU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IUystH1u3n_z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7O_zuUex3n8A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3htNkFVh3n5S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YCatlx9z3n1G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGZZTw9s-VxE"
   },
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "id": "suaMbV2KXPIR"
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "  def __init__(self, X, y):\n",
    "    super().__init__()\n",
    "    self.x = torch.tensor(X, dtype = torch.float)\n",
    "    self.y = torch.tensor(y, dtype = torch.float)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.y)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l-ii9itgX-tD",
    "outputId": "fcd2f94c-d202-44c0-dedc-23483765e51a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2982, 30])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BYC2rsL3XONP",
    "outputId": "2e5ab719-c745-47ad-907c-a7934d9def41"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-338-c43d058806c9>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.x = torch.tensor(X, dtype = torch.float)\n",
      "<ipython-input-338-c43d058806c9>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.y = torch.tensor(y, dtype = torch.float)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TextDataset(X_train, y_train)\n",
    "test_dataset = TextDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "id": "0J6l5ERrXOJX"
   },
   "outputs": [],
   "source": [
    "#dataset and loader\n",
    "trainloader = DataLoader(train_dataset, batch_size = 32)\n",
    "#dataset and loader\n",
    "testloader = DataLoader(test_dataset, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "id": "o6sdapW1-XpK"
   },
   "outputs": [],
   "source": [
    "# nn.LSTM()\n",
    "class BasicLSTM(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.rnn = nn.LSTM(input_size = 30,\n",
    "                    hidden_size = 100,\n",
    "                    num_layers = 1,\n",
    "                    batch_first = True)\n",
    "\n",
    "    self.lin1 = nn.Linear(in_features = 100, out_features=100)\n",
    "    self.lin2 = nn.Linear(in_features = 100, out_features = 1)\n",
    "    self.act = nn.ReLU()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x, (hn, cn)= self.rnn(x)\n",
    "    x = self.act(self.lin1(x))\n",
    "    x = self.lin2(x)\n",
    "    return self.sigmoid(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "id": "iRFR5kjC-Xlg"
   },
   "outputs": [],
   "source": [
    "model = BasicLSTM()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ltm2mqT-Xh3",
    "outputId": "b1aebd24-2dd5-426c-fa60-7e554fe48f80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 58.59839341044426\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "for epoch in range(10):\n",
    "  losses = 0\n",
    "  for x,y in trainloader:\n",
    "    yhat = model(x)\n",
    "    y = y.reshape(-1, 1)\n",
    "    loss = loss_fn(yhat, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses += loss.item()\n",
    "  if epoch % 10 == 0:\n",
    "    print(f'Epoch {epoch} Loss: {losses}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BAJowK6-Xee",
    "outputId": "0544bb9d-005a-4379-d868-7fec8e61c5e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-380-c8ba3076ae9b>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Xt = torch.tensor(X_test, dtype = torch.float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7024)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt = torch.tensor(X_test, dtype = torch.float)\n",
    "output = model(Xt)\n",
    "preds = np.where(np.array(output.detach()) >= .5, 1, 0)\n",
    "sum(preds[:, 0] == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "id": "6naIG8zXcMHu"
   },
   "outputs": [],
   "source": [
    "class RNN2(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.rnn = nn.GRU(input_size = 30,\n",
    "                    hidden_size = 30,\n",
    "                    num_layers = 2,\n",
    "                    batch_first = True)\n",
    "\n",
    "    self.lin1 = nn.Linear(in_features = 30, out_features=100)\n",
    "    self.lin2 = nn.Linear(in_features = 100, out_features = 1)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x, _ = self.rnn(x)\n",
    "    x = self.lin1(x)\n",
    "    x = self.lin2(x)\n",
    "    return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "id": "4rvMTz63cd56"
   },
   "outputs": [],
   "source": [
    "model = RNN2()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Usld0UXHcpWa",
    "outputId": "7039c5bb-ba9b-48f6-bff0-729520c0188d"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 59.61756247282028\n",
      "Epoch 10 Loss: 57.20614293217659\n",
      "Epoch 20 Loss: 55.79645165801048\n",
      "Epoch 30 Loss: 55.00879901647568\n",
      "Epoch 40 Loss: 55.988073855638504\n",
      "Epoch 50 Loss: 54.665479958057404\n",
      "Epoch 60 Loss: 53.79632553458214\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "for epoch in range(100):\n",
    "  losses = 0\n",
    "  for x,y in trainloader:\n",
    "    yhat = model(x)\n",
    "    y = y.reshape(-1, 1)\n",
    "    loss = loss_fn(yhat, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses += loss.item()\n",
    "  if epoch % 10 == 0:\n",
    "    print(f'Epoch {epoch} Loss: {losses}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7oxNBjhtcsoH",
    "outputId": "c95e9dd9-a4a9-4452-8e96-251210b0572a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6689)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xt = torch.tensor(sequences, dtype = torch.float)\n",
    "output = model(X_test)\n",
    "preds = np.where(np.array(output.detach()) >= .5, 1, 0)\n",
    "sum(preds[:, 0] == y_test.flatten())/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uG-M5_QSd_Le"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}