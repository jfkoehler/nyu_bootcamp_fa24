{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkMGC5qF6_Bw"
   },
   "source": [
    "# Text Classification and Recurrent Neural Networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6p825gZz1pky"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1V3dAQ5T1ph8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (3.13.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (1.26.4)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (15.0.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\r\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (2.2.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests>=2.32.2 (from datasets)\r\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm>=4.66.3 (from datasets)\r\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xxhash (from datasets)\r\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (12 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting multiprocess<0.70.17 (from datasets)\r\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiohttp (from datasets)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading aiohttp-3.11.9-cp312-cp312-macosx_10_13_x86_64.whl.metadata (7.7 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface-hub>=0.23.0 (from datasets)\r\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (23.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (6.0.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\r\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\r\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-macosx_10_13_x86_64.whl.metadata (13 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\r\n",
      "  Downloading multidict-6.1.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (5.0 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\r\n",
      "  Downloading propcache-0.2.1-cp312-cp312-macosx_10_13_x86_64.whl.metadata (9.2 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\r\n",
      "  Downloading yarl-1.18.3-cp312-cp312-macosx_10_13_x86_64.whl.metadata (69 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->datasets) (4.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading aiohttp-3.11.9-cp312-cp312-macosx_10_13_x86_64.whl (463 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\r\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading xxhash-3.5.0-cp312-cp312-macosx_10_9_x86_64.whl (31 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\r\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-macosx_10_13_x86_64.whl (54 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading multidict-6.1.0-cp312-cp312-macosx_10_9_x86_64.whl (29 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading propcache-0.2.1-cp312-cp312-macosx_10_13_x86_64.whl (45 kB)\r\n",
      "Downloading yarl-1.18.3-cp312-cp312-macosx_10_13_x86_64.whl (94 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: xxhash, tqdm, requests, propcache, multidict, fsspec, frozenlist, dill, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.66.2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Uninstalling tqdm-4.66.2:\r\n",
      "      Successfully uninstalled tqdm-4.66.2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: requests\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found existing installation: requests 2.31.0\r\n",
      "    Uninstalling requests-2.31.0:\r\n",
      "      Successfully uninstalled requests-2.31.0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: fsspec\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found existing installation: fsspec 2024.10.0\r\n",
      "    Uninstalling fsspec-2024.10.0:\r\n",
      "      Successfully uninstalled fsspec-2024.10.0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.9 aiosignal-1.3.1 datasets-3.1.0 dill-0.3.8 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.26.3 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.1 requests-2.32.3 tqdm-4.67.1 xxhash-3.5.0 yarl-1.18.3\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Var0y0mO1pf8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating test split:   0%|   | 0/3728 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating test split: 100%|█| 3728/3728 [00:00<00:00, 132866.2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"Paul/hatecheck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JCgkDaBR1pcs"
   },
   "outputs": [],
   "source": [
    "df = ds['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0rGV2gGr1pZ-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              I hate women. \n",
       "1       I hate trans people. \n",
       "2         I hate gay people. \n",
       "3       I hate black people. \n",
       "4    I hate disabled people. \n",
       "Name: test_case, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['test_case'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CyvCAU_w1pXg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_gold\n",
       "hateful        2563\n",
       "non-hateful    1165\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_gold'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JeOT3Un2JnL"
   },
   "source": [
    "### Encoding the Text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xC5Dl3xX1pVX"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8l-hCCFo1pTL"
   },
   "outputs": [],
   "source": [
    "cvect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "X4Kkp-7W1pQT"
   },
   "outputs": [],
   "source": [
    "dtm = cvect.fit_transform(df['test_case'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GUAyYobT2ttp"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2020</th>\n",
       "      <th>4ssholes</th>\n",
       "      <th>abhor</th>\n",
       "      <th>about</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutefilth</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>academics</th>\n",
       "      <th>accepted</th>\n",
       "      <th>accountants</th>\n",
       "      <th>...</th>\n",
       "      <th>writing</th>\n",
       "      <th>wrong</th>\n",
       "      <th>yeah</th>\n",
       "      <th>years</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yourselves</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2020  4ssholes  abhor  about  absolute  absolutefilth  absolutely  \\\n",
       "0     0         0      0      0         0              0           0   \n",
       "1     0         0      0      0         0              0           0   \n",
       "2     0         0      0      0         0              0           0   \n",
       "3     0         0      0      0         0              0           0   \n",
       "4     0         0      0      0         0              0           0   \n",
       "\n",
       "   academics  accepted  accountants  ...  writing  wrong  yeah  years  you  \\\n",
       "0          0         0            0  ...        0      0     0      0    0   \n",
       "1          0         0            0  ...        0      0     0      0    0   \n",
       "2          0         0            0  ...        0      0     0      0    0   \n",
       "3          0         0            0  ...        0      0     0      0    0   \n",
       "4          0         0            0  ...        0      0     0      0    0   \n",
       "\n",
       "   your  yours  yourself  yourselves  zoo  \n",
       "0     0      0         0           0    0  \n",
       "1     0      0         0           0    0  \n",
       "2     0      0         0           0    0  \n",
       "3     0      0         0           0    0  \n",
       "4     0      0         0           0    0  \n",
       "\n",
       "[5 rows x 1292 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dtm.toarray(), columns=cvect.get_feature_names_out()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xP_yzIBC1pNS"
   },
   "outputs": [],
   "source": [
    "X = dtm\n",
    "y = df['label_gold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrZ7TjOH2Zak"
   },
   "source": [
    "### Problem\n",
    "\n",
    "Split the data and build a random forest classifier on the training data.  Compare the train and test scores.  \n",
    "\n",
    "- What words were most important in making the classifications?\n",
    "- What elements of the CountVectorizer might you change or grid search to attempt to improve your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QjOyryQn2ZIB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fl7NA5Ek2ZE6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwZqNLIv2ZBy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n937sewV2Y-d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9kzCXAQ2Y7Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYVIyq1m2Y4h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SQWyog0AAOZ"
   },
   "source": [
    "# Text Classification with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "e0uc39GMhd70"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liI1vRV8hg2F"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAI5zZVn8Cp1"
   },
   "source": [
    "#### Classifying Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7ifGrEZhkoD"
   },
   "outputs": [],
   "source": [
    "#read in data\n",
    "spam = pd.read_csv('sms_spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "X_Qo7jH1hmeZ",
    "outputId": "abd21b76-0e39-4042-ee1e-3262aa456a73"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"spam\",\n  \"rows\": 5559,\n  \"fields\": [\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5156,\n        \"samples\": [\n          \"Thnx dude. u guys out 2nite?\",\n          \"How i noe... She's in da car now... Later then c lar... I'm wearing shorts...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "spam"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-d6fda6c5-c00c-4c56-8b0e-065659d2f36b\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hope you are having a good week. Just checking in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>K..give back my thanks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Am also doing in cbe only. But have to pay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>complimentary 4 STAR Ibiza Holiday or £10,000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>okmail: Dear Dave this is your final notice to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6fda6c5-c00c-4c56-8b0e-065659d2f36b')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-d6fda6c5-c00c-4c56-8b0e-065659d2f36b button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-d6fda6c5-c00c-4c56-8b0e-065659d2f36b');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-16e822ff-56ca-4d15-82d6-75a866912738\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-16e822ff-56ca-4d15-82d6-75a866912738')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-16e822ff-56ca-4d15-82d6-75a866912738 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham  Hope you are having a good week. Just checking in\n",
       "1   ham                            K..give back my thanks.\n",
       "2   ham        Am also doing in cbe only. But have to pay.\n",
       "3  spam  complimentary 4 STAR Ibiza Holiday or £10,000 ...\n",
       "4  spam  okmail: Dear Dave this is your final notice to..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a peek\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XOqnZA90i0vQ"
   },
   "outputs": [],
   "source": [
    "#create a tokenizer\n",
    "tokenizer = Tokenizer(num_words = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUWmDd-ik7MK"
   },
   "outputs": [],
   "source": [
    "#fit the tokenizer\n",
    "tokenizer.fit_on_texts(spam['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30pDdCd1sfsq",
    "outputId": "0bcf807e-75ff-460e-dddb-7a2e80740d4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at tokenizer\n",
    "tokenizer.num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZIs8UShtsfpg"
   },
   "outputs": [],
   "source": [
    "#create document term matrix (binarized)\n",
    "dtm = tokenizer.texts_to_matrix(spam['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJc6IxLe8cea",
    "outputId": "025f7fa7-d00b-4d60-cbc3-cb1fbddf2533"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a peek\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Q_WhuHe2CTPz",
    "outputId": "5cd43d63-75f0-49ea-8b94-4cee36283aa7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Am also doing in cbe only. But have to pay.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARFZcDfPCNnR"
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "  def __init__(self, X, y):\n",
    "    super().__init__()\n",
    "    self.x = torch.tensor(X, dtype = torch.float)\n",
    "    self.y = torch.tensor(y, dtype = torch.float)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.y)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDtzLOGbDvwQ"
   },
   "outputs": [],
   "source": [
    "X = dtm\n",
    "y = np.where(spam['type'] == 'ham', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sK-ekzymqkc3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aszcYuSVqkVo"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzIechzNqkR1",
    "outputId": "9e9c2d24-86eb-4463-c45c-9849ad9be859"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3kirParqkNg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5qkcKgO8et8"
   },
   "outputs": [],
   "source": [
    "#create data class\n",
    "train_dataset = TextDataset(X_train, y_train)\n",
    "test_dataset = TextDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MYZ6Jbws8eqS"
   },
   "outputs": [],
   "source": [
    "#dataset and loader\n",
    "trainloader = DataLoader(train_dataset, batch_size = 32)\n",
    "#dataset and loader\n",
    "testloader = DataLoader(test_dataset, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bpsixqUc8emJ"
   },
   "outputs": [],
   "source": [
    "#loss and optimizer\n",
    "class TextModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.lin1 = nn.Linear(in_features = 500, out_features = 100)\n",
    "    self.lin2 = nn.Linear(100, 100)\n",
    "    self.lin3 = nn.Linear(100, 1)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.act = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.act(self.lin1(x))\n",
    "    x = self.act(self.lin2(x))\n",
    "    return self.sigmoid(self.lin3(x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4h0spe_p8eie"
   },
   "outputs": [],
   "source": [
    "#training function\n",
    "model = TextModel()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXpxaYe88ece",
    "outputId": "bae31b17-ee29-497d-b3dd-b21f7db6541d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 17.463785945263226\n",
      "Epoch 10 Loss: 0.3230317887267802\n",
      "Epoch 20 Loss: 0.1858880319979619\n",
      "Epoch 30 Loss: 0.18419960872658825\n",
      "Epoch 40 Loss: 0.19837459240657174\n",
      "Epoch 50 Loss: 0.18659224085559767\n",
      "Epoch 60 Loss: 45.2216811845803\n",
      "Epoch 70 Loss: 6.432060421328064\n",
      "Epoch 80 Loss: 6.417951953306446\n",
      "Epoch 90 Loss: 6.412450148929762\n"
     ]
    }
   ],
   "source": [
    "#evaluate\n",
    "for epoch in range(100):\n",
    "  losses = 0\n",
    "  for x,y in trainloader:\n",
    "    yhat = model(x)\n",
    "    y = y.reshape(-1, 1)\n",
    "    loss = loss_fn(yhat, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses += loss.item()\n",
    "  if epoch % 10 == 0:\n",
    "    print(f'Epoch {epoch} Loss: {losses}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DcEHs4y8eZn"
   },
   "outputs": [],
   "source": [
    "Xt = torch.tensor(X_test, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aEy8zfP0HNr5"
   },
   "outputs": [],
   "source": [
    "\n",
    "output = model(Xt) #model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GVJHCGeqEJM",
    "outputId": "34039b4c-d9d0-40cf-d537-cc19920592ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1603e-23],\n",
       "        [4.3468e-08],\n",
       "        [2.5849e-02],\n",
       "        ...,\n",
       "        [0.0000e+00],\n",
       "        [0.0000e+00],\n",
       "        [1.3465e-31]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkVQymo1HUui"
   },
   "outputs": [],
   "source": [
    "#Converting probabilities to prediction\n",
    "preds = np.where(np.array(output.detach()) >= .5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhEbGWR8HUnh",
    "outputId": "417f614c-a9ce-4f1e-eb54-3f3d8444495b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1112, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UONO0UuHHUi1"
   },
   "outputs": [],
   "source": [
    "y = np.where(spam['type'] == 'ham', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppU6XUcLHrgv",
    "outputId": "0f4650ae-35b4-4432-bd4b-bbb4d0a5cd1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9784172661870504"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds[:, 0] == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPX_vybFrdkU",
    "outputId": "4a9031e9-e266-4b67-ee84-6ad14efaeeda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([972, 140]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Suftvk62rkFe",
    "outputId": "a70d9da2-dcd1-4b8c-b834-3e12f2655b35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8552158273381295"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "951/(951 + 161)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zajZdySD9Lxl"
   },
   "source": [
    "### Basic RNN\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Recurrent_neural_network_unfold.svg/440px-Recurrent_neural_network_unfold.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14ohZWmqlBXn"
   },
   "outputs": [],
   "source": [
    "#create sequences\n",
    "sequences = tokenizer.texts_to_sequences(spam['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1iAvE73XlGNf",
    "outputId": "41bd6e8e-6b39-43f1-849d-4f41a79377f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[122, 3, 22, 313, 4, 53, 110, 37, 8]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at first sequence\n",
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WBoD5QfPlK7X",
    "outputId": "628dbe30-56d1-4c5c-a944-4d79702c3f8e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'K..give back my thanks.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare to text\n",
    "spam['text'].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PmeaiuOAlNGD"
   },
   "outputs": [],
   "source": [
    "#pad and make all same length\n",
    "sequences = pad_sequences(sequences, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JH6zRxhxmlrt",
    "outputId": "68bb1f02-f055-4318-9435-04e954a2f8e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine results\n",
    "sequences[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dYw2vJpntRVx",
    "outputId": "dfbd1822-5ef5-4b92-b90b-ba93a4bec456"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,  92, 134,  86,  11, 170], dtype=int32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GnZn1epsSEi"
   },
   "outputs": [],
   "source": [
    "#example rnn\n",
    "rnn = nn.RNN(input_size = 100,\n",
    "             hidden_size = 30,\n",
    "             num_layers = 1,\n",
    "             batch_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fr2mNE_0swQp",
    "outputId": "1e81dafa-9a4b-4ef3-901e-0809c606d10d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pass data through\n",
    "sample_sequence = torch.tensor(sequences[1],\n",
    "                               dtype = torch.float,\n",
    "                               ).reshape(1, -1)\n",
    "sample_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97X1o7qHmw5n"
   },
   "outputs": [],
   "source": [
    "#output\n",
    "output, hidden = rnn(sample_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ONbv5VGa2EhR",
    "outputId": "7d4321ec-fab8-4904-fa20-e569679975d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9969,\n",
       "          1.0000,  1.0000,  1.0000,  0.9927, -0.9988,  1.0000,  1.0000, -1.0000,\n",
       "         -1.0000,  0.9980, -0.9968,  1.0000,  0.8639, -1.0000, -1.0000,  0.9869,\n",
       "          1.0000,  0.7625,  1.0000,  0.6461, -1.0000, -0.9947]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hidden\n",
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyjoR6x1tIRz",
    "outputId": "8c2df8df-df0c-4516-e129-6aa3952c9a17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linear layer\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wy86PysZh4yt"
   },
   "outputs": [],
   "source": [
    "#pass through linear\n",
    "lin1 = nn.Linear(in_features = 30, out_features = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H-24s8_ZMNQs",
    "outputId": "d2ece9af-1873-4375-8f9c-e82156c5dca4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1402]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin1(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SsLIq2RpMoe5",
    "outputId": "ce333b5e-e947-485c-fafd-277c6f90a4e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 500])\n"
     ]
    }
   ],
   "source": [
    "for x, y in trainloader:\n",
    "  print(x.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kss5sft0OosZ"
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "  def __init__(self, X, y):\n",
    "    super().__init__()\n",
    "    self.x = torch.tensor(X, dtype = torch.float)\n",
    "    self.y = torch.tensor(y, dtype = torch.float)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.y)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0N9mpg9h5og"
   },
   "outputs": [],
   "source": [
    "#class\n",
    "class BasicRNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.rnn = nn.RNN(input_size = 100,\n",
    "                    hidden_size = 100,\n",
    "                    num_layers = 3,\n",
    "                    batch_first = True)\n",
    "    self.lin1 = nn.Linear(in_features = 100, out_features=1000)\n",
    "    self.lin2 = nn.Linear(1000, 100)\n",
    "    self.lin3 = nn.Linear(100, 1)\n",
    "    self.act = nn.ReLU()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x, _ = self.rnn(x)\n",
    "    x = self.act(self.lin1(x))\n",
    "    x = self.act(self.lin2(x))\n",
    "    x = self.sigmoid(self.lin3(x))\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stjsLaxj5k40"
   },
   "outputs": [],
   "source": [
    "#data\n",
    "X = sequences\n",
    "y = np.where(spam['type'] == 'spam', 1, 0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)\n",
    "traindata = TextDataset(X_train, y_train)\n",
    "trainloader = DataLoader(traindata, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ACZI673-RpV"
   },
   "outputs": [],
   "source": [
    "#optimizer and loss\n",
    "model = BasicRNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLj-NUK5-TeE",
    "outputId": "cf947eb2-936d-4c06-c4f6-696e71c0c5cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 54.333703458309174\n",
      "Epoch 10 Loss: 49.14352545142174\n",
      "Epoch 20 Loss: 50.294177405536175\n",
      "Epoch 30 Loss: 54.339055240154266\n",
      "Epoch 40 Loss: 54.340724781155586\n",
      "Epoch 50 Loss: 54.34115116298199\n",
      "Epoch 60 Loss: 54.34125591814518\n",
      "Epoch 70 Loss: 54.341282427310944\n",
      "Epoch 80 Loss: 54.34128923714161\n",
      "Epoch 90 Loss: 54.34129001200199\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "for epoch in range(100):\n",
    "  losses = 0\n",
    "  for x,y in trainloader:\n",
    "    yhat = model(x)\n",
    "    y = y.reshape(-1, 1)\n",
    "    loss = loss_fn(yhat, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses += loss.item()\n",
    "  if epoch % 10 == 0:\n",
    "    print(f'Epoch {epoch} Loss: {losses}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_uQWrJaPRwA"
   },
   "outputs": [],
   "source": [
    "Xt = torch.tensor(X_test, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5XcG1OpPZ2T"
   },
   "outputs": [],
   "source": [
    "output = model(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwS2m5rcPZ2Z"
   },
   "outputs": [],
   "source": [
    "preds = np.where(np.array(output.detach()) >= .5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZgcoSgzM3Xt"
   },
   "outputs": [],
   "source": [
    "#preds = output.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izZ6GyxHwV2z",
    "outputId": "b49adcd4-e2d8-4df3-c413-c8d366e678d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8BeML_qPZ2Z"
   },
   "outputs": [],
   "source": [
    "# y = np.where(spam['type'] == 'ham', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtBc83hINEL4"
   },
   "outputs": [],
   "source": [
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GEhgDz-9wiP0",
    "outputId": "a49d8882-3221-461a-8355-d71a8b4c0a7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8588129496402878"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds.reshape(1112,) == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouZw-ftC3tcn"
   },
   "source": [
    "### Pretrained Models and HuggingFace\n",
    "\n",
    "- [Huggingface](https://huggingface.co/)\n",
    "- [Chronos Paper](https://arxiv.org/abs/2403.07815)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUfs4IFd3od3"
   },
   "outputs": [],
   "source": [
    "pip install git+https://github.com/amazon-science/chronos-forecasting.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1DWaYOa93oRa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from chronos import ChronosPipeline\n",
    "\n",
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "  \"amazon/chronos-t5-large\",\n",
    "  device_map=\"cuda\",\n",
    "  torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/AileenNielsen/TimeSeriesAnalysisWithPython/master/data/AirPassengers.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "np9GE5ch3oNw"
   },
   "outputs": [],
   "source": [
    "# context must be either a 1D tensor, a list of 1D tensors,\n",
    "# or a left-padded 2D tensor with batch as the first dimension\n",
    "context = torch.tensor(df[\"#Passengers\"])\n",
    "prediction_length = 12\n",
    "forecast = pipeline.predict(context, prediction_length)  # shape [num_series, num_samples, prediction_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lbH7HgtW3oLS"
   },
   "outputs": [],
   "source": [
    "# visualize the forecast\n",
    "forecast_index = range(len(df), len(df) + prediction_length)\n",
    "low, median, high = np.quantile(forecast[0].numpy(), [0.1, 0.5, 0.9], axis=0)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(df[\"#Passengers\"], color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(forecast_index, median, color=\"tomato\", label=\"median forecast\")\n",
    "plt.fill_between(forecast_index, low, high, color=\"tomato\", alpha=0.3, label=\"80% prediction interval\")\n",
    "plt.legend()\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCp8SfBdN4El"
   },
   "source": [
    "### Problem\n",
    "\n",
    "Explore the pretrained models available and try to find one that is either of relevance to your final paper or just of general interest.  Load and use the model in an example -- even just the docs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfk8Kugz3oHz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtsjogUW3oF6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9agE6Oi3oDU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IUystH1u3n_z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7O_zuUex3n8A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3htNkFVh3n5S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YCatlx9z3n1G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGZZTw9s-VxE"
   },
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6sdapW1-XpK"
   },
   "outputs": [],
   "source": [
    "# nn.LSTM()\n",
    "class BasicLSTM(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.rnn = nn.LSTM(input_size = 100,\n",
    "                    hidden_size = 100,\n",
    "                    num_layers = 1,\n",
    "                    batch_first = True)\n",
    "\n",
    "    self.lin1 = nn.Linear(in_features = 100, out_features=100)\n",
    "    self.lin2 = nn.Linear(in_features = 100, out_features = 1)\n",
    "    self.act = nn.ReLU()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x, _ = self.rnn(x)\n",
    "    x = self.act(self.lin1(x))\n",
    "    x = self.lin2(x)\n",
    "    return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRFR5kjC-Xlg"
   },
   "outputs": [],
   "source": [
    "model = BasicLSTM()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ltm2mqT-Xh3",
    "outputId": "f16974e7-e7be-4988-8c39-3ba6bfdeade9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 49.52611651271582\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "for epoch in range(10):\n",
    "  losses = 0\n",
    "  for x,y in trainloader:\n",
    "    yhat = model(x)\n",
    "    y = y.reshape(-1, 1)\n",
    "    loss = loss_fn(yhat, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses += loss.item()\n",
    "  if epoch % 10 == 0:\n",
    "    print(f'Epoch {epoch} Loss: {losses}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-BAJowK6-Xee"
   },
   "outputs": [],
   "source": [
    "Xt = torch.tensor(X_test, dtype = torch.float)\n",
    "output = model(Xt)\n",
    "preds = np.where(np.array(output.detach()) >= .5, 1, 0)\n",
    "sum(preds[:, 0] == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k63sNp5Q-Xa1"
   },
   "outputs": [],
   "source": [
    "#pad and make all same length\n",
    "sequences = pad_sequences(sequences, maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FEAht9gg-XWJ"
   },
   "outputs": [],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPTeRZtq-UM_"
   },
   "outputs": [],
   "source": [
    "X = sequences\n",
    "y = np.where(spam['type'] == 'spam', 1, 0)\n",
    "data = TextDataset(X, y)\n",
    "loader = DataLoader(data, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6naIG8zXcMHu"
   },
   "outputs": [],
   "source": [
    "class RNN2(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.rnn = nn.LSTM(input_size = 30,\n",
    "                    hidden_size = 30,\n",
    "                    num_layers = 2,\n",
    "                    batch_first = True)\n",
    "\n",
    "    self.lin1 = nn.Linear(in_features = 30, out_features=100)\n",
    "    self.lin2 = nn.Linear(in_features = 100, out_features = 1)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x, _ = self.rnn(x)\n",
    "    x = self.lin1(x)\n",
    "    x = self.lin2(x)\n",
    "    return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rvMTz63cd56"
   },
   "outputs": [],
   "source": [
    "model = RNN2()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Usld0UXHcpWa"
   },
   "outputs": [],
   "source": [
    "#train\n",
    "for epoch in range(100):\n",
    "  losses = 0\n",
    "  for x,y in loader:\n",
    "    yhat = model(x)\n",
    "    y = y.reshape(-1, 1)\n",
    "    loss = loss_fn(yhat, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses += loss.item()\n",
    "  if epoch % 10 == 0:\n",
    "    print(f'Epoch {epoch} Loss: {losses}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7oxNBjhtcsoH"
   },
   "outputs": [],
   "source": [
    "Xt = torch.tensor(sequences, dtype = torch.float)\n",
    "output = model(Xt)\n",
    "preds = np.where(np.array(output.detach()) >= .5, 1, 0)\n",
    "y = np.where(spam['type'] == 'ham', 0, 1)\n",
    "sum(preds[:, 0] == y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ac4PZ4Fec1U4"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JYGtpLBeITS"
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8oxkm34d0Ct"
   },
   "outputs": [],
   "source": [
    "spam['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2YyLU30d1_F"
   },
   "outputs": [],
   "source": [
    "preds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SF5ZdD7id6pl"
   },
   "outputs": [],
   "source": [
    "(y == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uG-M5_QSd_Le"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}