{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API's and Data Visualization\n",
    "\n",
    "This week we introduced working with an API to access data, and some additional plotting functionality through the `seaborn` library.  In the assignment, you will extract data from an API and use `matplotlib` and `seaborn` to visualize the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: You will need to sign up for Alpha Vantage's API and receive a key.  Also, you will need to navigate the documentation for the specified time series or sentiment data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1**\n",
    "\n",
    "Make sure to sign up for a new API Key from Alpha Vantage [here](https://www.alphavantage.co/).  Assign this key to the variable `api_key` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2**\n",
    "\n",
    "Extract the `TIME_SERIES_DALY` for Tesla and GM for years 2019 - present.  Draw side by side line plots using `matplotlib`.  Add appropriate titles and labels, adjust the figure size to `(20, 5)`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.alphavantage.co/query'\n",
    "req = requests.get(\n",
    "    base_url,\n",
    "    params={\n",
    "        \"function\": \"\",\n",
    "        \"symbol\": \"\",\n",
    "        \"apikey\": \"\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3**\n",
    "\n",
    "Extract the `TIME_SERIES_MONTHLY` for the Home Depot and Lowes.  Create a boxplot using `seaborn` where the $x$-axis is the month, and the $y$-axis is the closing price of each stock respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.alphavantage.co/query'\n",
    "req = requests.get(\n",
    "    base_url,\n",
    "    params={\n",
    "        \"function\": \"\",\n",
    "        \"symbol\": \"\",\n",
    "        \"apikey\": \"\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 4**\n",
    "\n",
    "Extract the `NEWS_SENTIMENT` for 200 articles related to Tesla stock.  Create a histogram of the sentiment scores from each article.  This boils down to extracting the `overall_sentiment_score` from each entry and plotting the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the parameters\n",
    "base_url = 'https://www.alphavantage.co/query'\n",
    "req = requests.get(\n",
    "    base_url,\n",
    "    params={\n",
    "        \n",
    "    }\n",
    ")\n",
    "results = req.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 5**\n",
    "\n",
    "Extract data related to retail sales from the last decade.  Create a side by side line plot and a boxplot for each month.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the parameters\n",
    "base_url = 'https://www.alphavantage.co/query'\n",
    "req = requests.get(\n",
    "    base_url,\n",
    "    params={\n",
    "        \n",
    "    }\n",
    ")\n",
    "results = req.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 6**\n",
    "\n",
    "Extract `REAL_GDP_PER_CAPITA` and fix the data so as to have a datetime index sorted from earliest to latest date.  Create a line plot using seaborn with appropriate labels and titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 7**\n",
    "\n",
    "Use the `yfinance` library to extract balance sheet data from two companies and determine the better investment using criteria of your choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 8**\n",
    "\n",
    "Using the `yfinance` library, extract data for five ticker symbols from 2018 through present.  Create a grid of scatterplots with a regression line [using seaborns regplot](http://seaborn.pydata.org/tutorial/regression.html) of the different tickers closing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 9**\n",
    "\n",
    "Read through the documentation on the `resample` method in pandas [here](https://pandas.pydata.org/docs/user_guide/timeseries.html#resampling).  Use the resample method to extract the first closing price of the month for Apple stock since 2012.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 10**\n",
    "\n",
    "Read through the user guide on the `rolling` methods in pandas [here](https://pandas.pydata.org/docs/user_guide/window.html#rolling-window).  Use this to create side by side line plots of the closing price of NVIDIA stock since 2018 and the rolling 20 day mean for the closing price of NVIDIA.  What effect does the rolling mean have on the plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 11**\n",
    "\n",
    "arXiv is an open source space for academic papers to be published.  They have a freely accessible API [here](https://info.arxiv.org/help/api/user-manual.html#arxiv-api-users-manual).  In order to parse the responses, you will need to use the BeautifulSoup library and turn the text of the response into a soup object that is then searched.\n",
    "\n",
    "Your objective is to write a function that takes in a search term and returns a `DataFrame` with the article date, title, authors, summary, and article url as columns of the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arXiv_data(search_terms):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 12**\n",
    "\n",
    "The world bank has a Python wrapper for its api called `wbgapi`.  Examine the documentation [here](https://pypi.org/project/wbgapi/) and chose an endpoint(s) to query.  Find at least two endpoints of interest and create visualizations of this data.  Write a sentence or two about what you've found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 13**\n",
    "\n",
    "Use `requests` and `BeautifulSoup` to scrape and format the most recent 100 album reviews from [Pitchfork](https://pitchfork.com/reviews/albums/).  Create a `DataFrame` that includes the album, artist, genre, reviewer, score, and review text for each of these albums. Write your `DataFrame` to a `.csv` file called `pitchfork_reviews.csv`.\n",
    "\n",
    "**HINT**: An important part of this will be to extract a url to the full review and use it to make another request from which you can pull the score and review text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 14**\n",
    "\n",
    "Find an api of interest to you.  Ask a specific question that you want to use the data from the api to answer, make an appropriate request of the endpoints and do your best to provide an answer to your question asked.\n",
    "\n",
    "-------\n",
    "For example, maybe I'm interested in finding out recent artists similar to Rod Stewart.  I could use the LastFM api for this.  Perhaps you're interested in a lyrical analysis of Drake vs. Kendrick Lamar -- and want to compare the lexical diversity of different tracks; you can use the genius api for this.  Maybe I want to build an app to show a random cat picture with a dad joke.  The cat api and jokes api might work here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 15**\n",
    "\n",
    "Use the `praw` api [here](https://praw.readthedocs.io/en/stable/) to extract posts from the `r/nyu` subreddit.  What posts are getting the most activity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BONUS**\n",
    "\n",
    "Using the [Dog API](https://dog.ceo/dog-api/), create a 2 X 5 grid of images of random dogs.  You will need to create subplots and you can use the axes `.imshow()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
